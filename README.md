# About
Xenium is a partially-destructive, highly multiplexed in-situ hybridization method in which the finished slide can still be used for certain staining (H&E and some antibodies (not CODEX)) protocols. In order to best interpret the output of these slides with each other it is best if we can align the post-Xenium stained image (such as H&E) with the dapi image generated by Xenium. This will then allow you to evaluate the accuracy of cell segmentation as well as better interpret localization of transcripts in the tissue morphology. Depending on how you run it this pipeline can take anywhere from 5 minutes to 20 minutes to run for a section that takes a quarter to half a Xenium slide. Most of that time is just writing the image output files.

# Preparing input files
To run this pipeline you need only 2 input files:
1. the dapi image from the xenium run. This is found in the Xenium output run folder and is called morphology_mip.ome.tif
1. the image of the stained slide. The input image can be a .qptiff, a .tiff, a .tif, or a .ome.tif file. I haven't tried other image formats.
    - In some instances if an image of the entire slide is taken and you may want to first crop out the region of interest with the desired piece of tissue on it. To do this follow the below instructions sourced from https://forum.image.sc/t/how-to-crop-an-image/73550:
        - Open the H&E image with [QuPath](https://qupath.github.io/) . 
        - Select the rectangular annotation drawing tool in the top left (alternatively: from the top menu drop-down Tools > rectangle)
        - Draw a rectangular box around the tissue that matches the desired Xenium sample. Do not click anywhere else in the image. The box needs to stay selected (yellow). If it is not selected (yellow), then you need to click the edge of the box so it is selected (yellow).
        - While the box is still selected go to File > Export Images > OME TIFF.
        - Change the settings to the following:
            - Compression type: ZLIB (lossless)
            - Pyramidal downsample: 2
            - Tile size: 1024 px
            - Parallelize export (if this is checked then it exports faster but takes more memory)
    - if you initially align the one image and then retake the image with the a microsope you will need to re-align the second image to the Xenium dapi image and the results will differ.
    - If you want to re-take the image of a specific region of interest instead of the full slide, then you should still be able to align it with this tool by saving the image as a raw tif file, but I have not tested it. You will need to take a image large enough that sufficient keypoint matches are found and I do not know what that size might be. I typically use this script to align 20X magnification H&E images.

# Example commands
To run this tool you need a python environment with numpy, OpenCV (cv2), tifffile, and optparse, (future plan to also use ome_types package). I have tested this in python 3.9 and python 3.10. You can clone the environment I have previously used to run the tools as follows:
```
conda create --name hexsift --file py3.10_spec_file_2023-10-16.txt
conda env create -f py3.10_environment.yml --name hexsift
```
If you do not yet have Anaconda installed on your lab cluster then please see the [Conda Installation on Linux](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html) guide for how to do so.
This tools only requires the following script to run:
```
image_opencv_sift_v9.py
```
## Options
There are currently 2 flags that you will need to use every time you run the command and one additional flag you may need to use depending on your image:
* `-i` or `--image` is the path to the image file that you will be aligning to the Xenium dapi image. For now this should be an H&E image. If it is an image of a fluorescent antibody stain, then channel that contains dapi needs to be the first image (channel) stored in the input image file (i.e the first channel in axis 3 he_image[:,:,0]). For now if it is not then you will have to re-order the image channels and re-save the image. One way of doing this is by using the provided `writing_ome_tif_v9.py` script. `python writing_ome_tif_v9.py -i <your_image_file.tif> -s <name_you_want_the_output_file_to_be>`. I may update the script later to add an option that lets you specify the channel that has dapi. 
* `-d` or `--dapi` is used to specify the path to the Xenium dapi image from the xenium output files. This is the image that output image is aligned to. This image is not warped or shifted during the alignment process. It should be a uint16 (unsigned 16-bit integer) scaled image file from the Xenium sample output folder called `morphology_mip.ome.tif`.
* `-f` or `--flip` is the flag you will need to use if your image also needs to be flipped. SIFT only allows for your image to be translated (moved up/down/left/right), rotated, or scaled (shrink/stretch). It does not allow for images to be flipped or transposed (transposed = rotated and then flipped). **If your image needs to be flipped or transposed then you need to use this flag when running your pipeline. If you do not use this flag then your output will look extremely warped or like you are falling down in a cliff while looking up at the rising edges of said cliff. If you bring the results of this pipeline to me and tell me it did not work with something that looks like what I just described, then this is the first thing that I will ask you about. The second thing I will ask is if you used the H&E image from the same sample as the Xenium dapi image or if you swapped images from different samples.**
There are 3 optional flags that can improve your results.
* `-b` is the flag you will use when you want to specify for the script to only use the blue channel of the image. This results in the alignment only relying on the first image channel (blue) of the BGR (Blue, Green, Red) channels that all bright-field images include. In otherwords the output will only rely on `he_image[:,:,0]`. **Generally I find using this flag improves the overall alignment for all samples I have tried it with so far.** In addition though for some samples it is needed to ensure a high-quality alignment. This is because the `morphology_mip.ome.tif` only contains a dapi stain of the nuclei on a Xenium slide. The H&E stain of that same slide stains the slide pink and purple with most of that purple being present in the nuclei. Therefore the To align the slide we need to create a grayscale image and if one part of that image is a intense red it is because there are few to no nuclei there and that signal will not be present anywhere in the Xenium image you are aligning to. To get around this we can filter the image to only the blue pixel values since the most intense blue pixel values are typically found in the cell nuclei of the H&E slide. If parts of your aligned output do not properly overlap the Xenium dapi image then use this flag if you are not already.
* `-s` or `--scaling` is the flag you use to specify how much the image is down-scaled when the image is aligned. Specify a whole number from 0-7. Default is 4. It is not recommended that you change this value for an initial alignment beyond those values suggested below in the example commands. This is the level of dapi and H&E image downscaling that will be used to calculate the Homograpphy matrix for image alignment. A level of 4 means that the Y and X axes of the H&E image will be divided by 2^4 (i.e. 16) during initial homography matrix calculation. The Homography matrix will then be scaled back up by the resulting scale matrix for use in the full size H&E alignment.
* `-m` or `--matches_limit` is used to specify any whole number less than the total number of keypoint matches found. Default is 20. It is not recommended that you change this value for an initial alignment beyond those values suggested below in the example commands. Keypoints and their descriptors of an image are identified using the SIFT algorithm and they are then matched using a FLANN matcher. The top n keypoint matches are then used for image alignment. If there are a large number of potentially good keypoint matches then increasing this number can improve the alignment. Otherwise decreasing it can hurt the alignment. When the script runs normally part of the stdout states something along the lines `Number of good matches: 248`. So long as the value of `-m` is less than the value printed to stdout in that line your alignment should be of decent quality and the script will not crash. If you decrease the downscaling of the image prior to alignment (use a smaller value for `-s` then you should generally provide a larger value with `-m`)
## Command
The following are some example commands:

NOTE: To date I have found the highest quality alignments to be generated when using the flags: `-b -s 0 -m 60`. However the total size of all the output files combined is much larger, it can use a lot more memory (200GB+ due to the number of keypoints being identified on the imge) and the script takes much longer to run (most of this additional time is just from writing all of the output files), also during SIFT keypoint detection the memory can easily take up half of a 500GB node if this option is used. Most of the output files are just QC and used to keep track of which parts of the image are used to generate the alignment. The equivalent to these commands that the script uses by default is `-s 4 -m 20` (uses closer to 30-70GB). A good middle ground is `-b -s 2 -m 40`. Including more keypoint matches and using the full resolution image is not always a good thing as incorrect matches can still be found which is why we don't just use all keypoint matches. We only want to take the highest quality keypoint matches. The large memory problem is something that I am planning on addressing in the future. Note that the extreme memory usage can probably be addressed by tiling over the image when identifying keypoints (would then need to loop over all keypoints and check to make sure they are all unique) and I just haven't had time to do that yet, but plan to do so in the future.

**Example when the image needs to be flipped**
```
cd /folder/where/your/want/the/output/to/be
python3 /path/to/HEX-SIFT/image_opencv_sift_v9.py -i /path/to/image_RAW.tif -d /path/to/Xenium/folder/morphology_mip.ome.tif -f 
```
**Example when the image needs to be flipped and using only the blue pixel values for alignment**
```
cd /folder/where/your/want/the/output/to/be
python3 /path/to/HEX-SIFT/image_opencv_sift_v9.py -i /path/to/image_RAW.ome.tif -d morphology_mip.ome.tif -f -b
```
**Example using only the blue pixel values for alignment with less downscaling of the images and more keypoints for homography matrix calculation**
```
cd /folder/where/your/want/the/output/to/be
python3 /path/to/HEX-SIFT/image_opencv_sift_v9.py -i /path/to/image_crop.ome.tif -d /path/to/Xenium/folder/morphology_mip.ome.tif -b -s 2 -m 40
```
**Example using only the blue pixel values for alignment with no downscaling of the images and more keypoints for homography matrix calculation**
```
cd /folder/where/your/want/the/output/to/be
python3 /path/to/HEX-SIFT/image_opencv_sift_v9.py -i image_crop.ome.tif -d /path/to/Xenium/folder/morphology_mip.ome.tif -b -s 0 -m 60
```

# Evaluating the output quality
There are 17 files that are generated by this tool. The vast majority are for the purposes of QC and debugging when necessary. The 3 files that you will need as output are as follows:
* `Dapi_stacked_with_HE_aligned.ome.tif` - This file contains two tiled, pyramidal, zlib-compressed images in it. Each image is stored as a separate channel. The first channel is the dapi image that is input when the script is run using the `-d` flag. The second image is the aligned greyscale of the H&E image (or whatever image is input with the `-i` flag. The dapi image is not the original dapi image however. The original dapi image is scaled from 0 to 65535 (the unsigned 16-bit integer limit = (2^16)-1). The dapi image in this file has been rescaled from 0 to 255 (the unsigned 8-bit integer (uint8) limit). This allows the image to be viewed in imageJ and QuPath and at the same time compared to the other image in the file which is scaled from 0 to 255 (uint8 limit). To view this image open [Fiji](https://imagej.net/software/fiji/downloads). The go to Plugins > Bio-Formats > Bio-Formats Importer. Then use the browser to navigate to and select the `Dapi_stacked_with_HE_aligned.ome.tif` image. You will then see a menu of options. On the top left change the drop down to "Hyperstack" (the channels field should then automatically change to "XYCZT"). If you want to see image metadata then check the box that says "Open Image Metadata". Then click okay and when you see a menu of image options appear uncheck the box next to "Series 1" **If you do not unckeck the box next to Series 1 there is a large chance that the image will fail to open if you system does not have enough memory.** Scroll until you find an image size less than ~14,000 x ~14,000 pixels and check the box next to that Series. You can then open the image using the button at the bottom. From here you can use Fiji to navigate around the image using the hand tool to move left/right/up/down, the up/down arrow keys to zoom in and out, the left and right arrow keys to swap back and forth from the H&E image to the dapi image.
* `he_aligned.ome.tif` - This file is an ome tif that contains the full color aligned H&E image. You can inspect the aligned image in QuPath. If you want to use the aligned H&E image for other analysis in Xenium Explorer, Python or R this is also the file that you should use. See below for how to view this image in 10X Genomics Xenium Explorer. 
* `he_aligned.imageJ.ome.tif` - This file contains the same aligned H&E image as before but it is saved in a slightly different format so that the image can be read by imageJ. You will not need this image unless you want to look at your image in imageJ. If you do then follow the instructions under the `Dapi_stacked_with_HE_aligned.ome.tif` file to open the image in Fiji.
A brief description of the remaining files:
* `found.tif` - This file contains the downscaled version of the grayscale H&E image that is the output of the shrunk image that is used to find the homography matrix that is used in the final scaled up alignment. If you use `-s 0` when you run the script then this file is just the full size grayscaled H&E image.
* `found_full_res.tif` - the full resolution version of the aligned grayscaled H&E image. This is a grayscale of the final he_aligned.ome.tif that is used for subsequent analysis.
* `matched.tif` - This image file shows the matching keypoints that were used to calculate the homography between the dapi image and the H&E image. All keypoints are circled. Matching keypoints are connected by a line.
* `he_blue.tif` - This is the blue pixel values of the H&E image. If the `-b` flag is used this is the image that is used identify keypoints and generate the homography matrix.
* `he_red.tif` - This is the red pixel values of the H&E image. If the `-b` flag is used this channel is not used to identify keypoints and generate the homography matrix. If any large region of this image is near black then it is a good idea to use the `-b` flag.
* `he_green.tif` - This is the green pixel values of the H&E image. If the `-b` flag is used this channel is not used to identify keypoints and generate the homography matrix. If any large region of this image is near black then it is a good idea to use the `-b` flag.
* `he_small.tif` - This is the grayscaled H&E image pre-image thresholding and alignment. If the `-b` flag is used this s just the blue pixel/channel values of the H&E image.
* `he_thresh.tif` - This is the blurred ((Gaussian blur (3,3)), thresholded (cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) image generated from the grayscaled H&E image.
* `he_close.tif` - This is morphological close (disk 9x9) of the blurred, thresholded, grayscale H&E image.
* `he_erode_2.tif` - This is the mask that is applied to the grayscaled H&E image. It is generated by eroding the H&E `he_close.tif` image 2 times using a disk ellipse (2,2). 
* `he_masked.tif` - This is the masked grayscale H&E image. 
* `channels.pickle` - This is a pickle dump of the following list: `[dapi_image_scale_0_255, found_large]`. `dapi_image_scale_0_255` is the dapi image rescaled from np.uint16 (0-65535) to np.uint8 (0-255). `found_large` is the aligned full resolution H&E image provided no image dimension is larger than 32766 pixels (see troubleshooting). 
* `he_aligned.pickle` - This is a pickle dump of the aligned full-resolution, RGB-colored H&E image.

# Importing aligned images into Xenium Browser
If you plan on importing the image into Xenium Explorer then you should do so using the `he_aligned.ome.tif` image. To do so open the `experiment.xenium` file from the Xenium output files. Then select the "Image" drop down. Click the "Add image" button. Click "Import Image". Navigate to your downloaded `he_aligned.ome.tif` file and select it. Wait for a the browser to show a window with a small version of your H&E image (this may take a minute or two). Give the H&E image a name and click "Continue". At the next pop-up select "Yes, skip alignment" and click "Done".

# Troubleshooting
* Error cv2.error: OpenCV(4.6.0) /croot/opencv-suite_1691620365762/work/modules/imgproc/src/imgwarp.cpp:1724: error: (-215:Assertion failed) dst.cols < SHRT_MAX && dst.rows < SHRT_MAX && src.cols < SHRT_MAX && src.rows < SHRT_MAX in function 'remap' 
    * Solution: this error results because the aligned image is larger than the signed 16-bit integer limit (16-bit signed integer ranging from -32,768 to +32,767). I have now updated the script to resize images before keypoint, homography, and image warp so that the largest dimension is less than 32766 pixels. Any image larger than this will result in a crash in the openCV cv2.warpPerspective() function. There were two options for addressing this 1. using either a tiling approach or 2. first scaling the image down and then scaling it back up. If we used a tiling approach each tile has to be aligned separately and would then need to be stiched together. Stitching would require image alignment to each other after dapi alignment which could reduce the quality of the dapi alignment. Scaling will result in some loss of information and may not be a good solution for large pieces of tissue where 1 piece takes up the full xenium slide. I am not sure how much signal loss this will result in, but the final H&E image will at least be aligned optimally with the dapi image, which is something that stitching may not do.
        * Decided to go with the Image rescaling solution since optimal Xenium alignment is the current goal. It is done by first checking if any of the image dimensions are larger than 32766 pixels long. If the image is smaller, then that image is left unchanged. The unscaled image is then aligned. If the image is larger than that limit, then it is scaled down so that the largest image dimension is 1 pixel smaller than the 16-bit signed integer limit. The scaled down image is then aligned.
